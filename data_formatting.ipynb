{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqePa89Zb8O2"
   },
   "source": [
    "# Data formatting\n",
    "\n",
    "In this script the data is formatted to fit the different models and variable settings used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8825,
     "status": "ok",
     "timestamp": 1654849057806,
     "user": {
      "displayName": "Oriol Pomarol",
      "userId": "08254266036031937194"
     },
     "user_tz": -120
    },
    "id": "5g1sRn2mZUn3",
    "outputId": "35f5ec00-4e75-4de2-8979-71cf326770c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "TIME_STEPS = 60     #positive integer, number of lagged variables, set to 1 for no lag\n",
    "TEST_SPLIT = 0.2    #fraction of the data to be used as test set\n",
    "LOCATION = 'lobith' #location of the data to be plotted\n",
    "\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#set input and output folders\n",
    "in_folder = '/content/drive/MyDrive/ADS/Final Thesis Project/data/'\n",
    "out_folder = f'/content/drive/MyDrive/ADS/Final Thesis Project/temp/formatted_data/{LOCATION}/'\n",
    "\n",
    "#read the data\n",
    "pred = pd.read_csv(in_folder + f'pred_{LOCATION}.csv')\n",
    "q = pd.read_csv(in_folder + f'q_{LOCATION}.csv')\n",
    "\n",
    "#define some more parameters based on previous ones\n",
    "n_obs = pred.shape[0] - (TIME_STEPS - 1)\n",
    "test_window = int(n_obs*TEST_SPLIT)\n",
    "is_lag = TIME_STEPS > 1\n",
    "\n",
    "#define function to find the year day\n",
    "def date_to_yday(date):\n",
    "  datetime_obj = datetime.strptime(date, '%Y-%m-%d')\n",
    "  yday = datetime_obj.timetuple().tm_yday\n",
    "  return yday\n",
    "\n",
    "#add day of the year in predictors\n",
    "pred['year_day'] = pred['datetime'].apply(date_to_yday)\n",
    "\n",
    "#remove the first column (date)\n",
    "pred = pred.iloc[:,1:]\n",
    "\n",
    "if is_lag:\n",
    "  #add the lagged variables to the dataframe\n",
    "  for i, var in enumerate(pred.columns):\n",
    "    for step in range(0, TIME_STEPS - 1):\n",
    "      pred.insert(i*(TIME_STEPS) + 1, \n",
    "                        f'{var}_lag_{TIME_STEPS - 1 - step}', \n",
    "                        pred[var].shift(TIME_STEPS - 1 - step))\n",
    "\n",
    "  #remove the first TIME_STEPS - 1 rows since they will contain NA values\n",
    "  pred = pred.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)\n",
    "  q = q.iloc[TIME_STEPS - 1:,:].reset_index(drop=True)\n",
    "\n",
    "#loop for every different testing sample\n",
    "for i,test_start in enumerate(range(0,n_obs - 1,test_window), start = 1):\n",
    "\n",
    "  #split train and test for predictors vars\n",
    "  X_train = pd.concat([pred.iloc[0:test_start, :], \n",
    "                       pred.iloc[test_start+test_window:, :]]\n",
    "                      ).to_numpy()\n",
    "  X_test = pred.iloc[test_start:test_start+test_window, :].to_numpy()\n",
    "\n",
    "  #split train and test for predicted var\n",
    "  y_train = pd.concat([q.iloc[0:test_start, -1], \n",
    "                       q.iloc[test_start+test_window:, -1]]\n",
    "                      ).to_numpy()\n",
    "  y_test = q.iloc[test_start:test_start+test_window, -1].to_numpy()\n",
    "\n",
    "  #extract the observations\n",
    "  obs = q.iloc[test_start:test_start+test_window, 1].to_numpy()\n",
    "  \n",
    "  #normalize the input\n",
    "  scaler = StandardScaler()\n",
    "  X_train[:,range(0, X_train.shape[1], TIME_STEPS)] = scaler.fit_transform(X_train[:,range(0, X_train.shape[1], TIME_STEPS)])\n",
    "  X_test[:,range(0, X_train.shape[1], TIME_STEPS)] = scaler.transform(X_test[:,range(0, X_train.shape[1], TIME_STEPS)])\n",
    "  for step in range(1,TIME_STEPS):\n",
    "    X_train[:,range(step, X_train.shape[1], TIME_STEPS)] = scaler.transform(X_train[:,range(step, X_train.shape[1], TIME_STEPS)])\n",
    "    X_test[:,range(step, X_train.shape[1], TIME_STEPS)] = scaler.transform(X_test[:,range(step, X_train.shape[1], TIME_STEPS)])\n",
    "    \n",
    "  scaler_params = scaler.get_params()\n",
    "  with open(out_folder + 'lagged_'*is_lag + f'scaler_params_{i}.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_params, f)\n",
    "  \n",
    "  #save all the data\n",
    "  np.savez(out_folder + 'no_'*(not is_lag) + f'lag_{i}',\n",
    "           X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test, obs = obs)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNNiE6owX5r0PUZshP8Ik+D",
   "collapsed_sections": [],
   "mount_file_id": "1QmSjtMMPpVBpXvDEC3ltai6tlSXFVl6D",
   "name": "data_formatting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
